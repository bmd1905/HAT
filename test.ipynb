{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disable distributed.\n",
      "Path already exists. Rename it to /Users/bmd1905/Desktop/HAT/results/HAT_SRx2_ImageNet-pretrain_archived_20230415_090058\n",
      "2023-04-15 09:00:58,063 INFO: \n",
      "                ____                _       _____  ____\n",
      "               / __ ) ____ _ _____ (_)_____/ ___/ / __ \\\n",
      "              / __  |/ __ `// ___// // ___/\\__ \\ / /_/ /\n",
      "             / /_/ // /_/ /(__  )/ // /__ ___/ // _, _/\n",
      "            /_____/ \\__,_//____//_/ \\___//____//_/ |_|\n",
      "     ______                   __   __                 __      __\n",
      "    / ____/____   ____   ____/ /  / /   __  __ _____ / /__   / /\n",
      "   / / __ / __ \\ / __ \\ / __  /  / /   / / / // ___// //_/  / /\n",
      "  / /_/ // /_/ // /_/ // /_/ /  / /___/ /_/ // /__ / /<    /_/\n",
      "  \\____/ \\____/ \\____/ \\____/  /_____/\\____/ \\___//_/|_|  (_)\n",
      "    \n",
      "Version Information: \n",
      "\tBasicSR: 1.3.4.9\n",
      "\tPyTorch: 2.0.0\n",
      "\tTorchVision: 0.15.1\n",
      "2023-04-15 09:00:58,064 INFO: \n",
      "  name: HAT_SRx2_ImageNet-pretrain\n",
      "  model_type: HATModel\n",
      "  scale: 2\n",
      "  num_gpu: 0\n",
      "  manual_seed: 0\n",
      "  datasets:[\n",
      "    test_1:[\n",
      "      name: Set5\n",
      "      type: PairedImageDataset\n",
      "      dataroot_gt: ./datasets/Set5/GTmod2\n",
      "      dataroot_lq: ./datasets/Set5/LRbicx2\n",
      "      io_backend:[\n",
      "        type: disk\n",
      "      ]\n",
      "      phase: test\n",
      "      scale: 2\n",
      "    ]\n",
      "  ]\n",
      "  network_g:[\n",
      "    type: HAT\n",
      "    upscale: 2\n",
      "    in_chans: 3\n",
      "    img_size: 64\n",
      "    window_size: 16\n",
      "    compress_ratio: 3\n",
      "    squeeze_factor: 30\n",
      "    conv_scale: 0.01\n",
      "    overlap_ratio: 0.5\n",
      "    img_range: 1.0\n",
      "    depths: [6, 6, 6, 6, 6, 6]\n",
      "    embed_dim: 180\n",
      "    num_heads: [6, 6, 6, 6, 6, 6]\n",
      "    mlp_ratio: 2\n",
      "    upsampler: pixelshuffle\n",
      "    resi_connection: 1conv\n",
      "  ]\n",
      "  path:[\n",
      "    pretrain_network_g: ./experiments/pretrained_models/HAT_SRx2_ImageNet-pretrain.pth\n",
      "    strict_load_g: True\n",
      "    param_key_g: params_ema\n",
      "    results_root: /Users/bmd1905/Desktop/HAT/results/HAT_SRx2_ImageNet-pretrain\n",
      "    log: /Users/bmd1905/Desktop/HAT/results/HAT_SRx2_ImageNet-pretrain\n",
      "    visualization: /Users/bmd1905/Desktop/HAT/results/HAT_SRx2_ImageNet-pretrain/visualization\n",
      "  ]\n",
      "  val:[\n",
      "    save_img: True\n",
      "    suffix: None\n",
      "    metrics:[\n",
      "      psnr:[\n",
      "        type: calculate_psnr\n",
      "        crop_border: 2\n",
      "        test_y_channel: True\n",
      "      ]\n",
      "      ssim:[\n",
      "        type: calculate_ssim\n",
      "        crop_border: 2\n",
      "        test_y_channel: True\n",
      "      ]\n",
      "    ]\n",
      "  ]\n",
      "  dist: False\n",
      "  rank: 0\n",
      "  world_size: 1\n",
      "  auto_resume: False\n",
      "  is_train: False\n",
      "\n",
      "2023-04-15 09:00:58,065 INFO: Dataset [PairedImageDataset] - Set5 is built.\n",
      "2023-04-15 09:00:58,065 INFO: Number of test images in Set5: 5\n",
      "/Users/bmd1905/miniforge3/envs/yolov7_env/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3484.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "2023-04-15 09:00:58,462 INFO: Network [HAT] is created.\n",
      "2023-04-15 09:00:58,469 INFO: Network: HAT, with parameters: 20,624,795\n",
      "2023-04-15 09:00:58,469 INFO: HAT(\n",
      "  (conv_first): Conv2d(3, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (patch_unembed): PatchUnEmbed()\n",
      "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "  (layers): ModuleList(\n",
      "    (0): RHAG(\n",
      "      (residual_group): AttenBlocks(\n",
      "        (blocks): ModuleList(\n",
      "          (0): HAB(\n",
      "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (conv_block): CAB(\n",
      "              (cab): Sequential(\n",
      "                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (1): GELU(approximate='none')\n",
      "                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (3): ChannelAttention(\n",
      "                  (attention): Sequential(\n",
      "                    (0): AdaptiveAvgPool2d(output_size=1)\n",
      "                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "                    (2): ReLU(inplace=True)\n",
      "                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1))\n",
      "                    (4): Sigmoid()\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1-5): 5 x HAB(\n",
      "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (conv_block): CAB(\n",
      "              (cab): Sequential(\n",
      "                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (1): GELU(approximate='none')\n",
      "                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (3): ChannelAttention(\n",
      "                  (attention): Sequential(\n",
      "                    (0): AdaptiveAvgPool2d(output_size=1)\n",
      "                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "                    (2): ReLU(inplace=True)\n",
      "                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1))\n",
      "                    (4): Sigmoid()\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (overlap_attn): OCAB(\n",
      "          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "          (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "          (unfold): Unfold(kernel_size=(24, 24), dilation=1, padding=4, stride=16)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (patch_embed): PatchEmbed()\n",
      "      (patch_unembed): PatchUnEmbed()\n",
      "    )\n",
      "    (1-5): 5 x RHAG(\n",
      "      (residual_group): AttenBlocks(\n",
      "        (blocks): ModuleList(\n",
      "          (0-5): 6 x HAB(\n",
      "            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (conv_block): CAB(\n",
      "              (cab): Sequential(\n",
      "                (0): Conv2d(180, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (1): GELU(approximate='none')\n",
      "                (2): Conv2d(60, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (3): ChannelAttention(\n",
      "                  (attention): Sequential(\n",
      "                    (0): AdaptiveAvgPool2d(output_size=1)\n",
      "                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "                    (2): ReLU(inplace=True)\n",
      "                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1))\n",
      "                    (4): Sigmoid()\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (drop_path): DropPath()\n",
      "            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (overlap_attn): OCAB(\n",
      "          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "          (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "          (unfold): Unfold(kernel_size=(24, 24), dilation=1, padding=4, stride=16)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (patch_embed): PatchEmbed()\n",
      "      (patch_unembed): PatchUnEmbed()\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv_after_body): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv_before_upsample): Sequential(\n",
      "    (0): Conv2d(180, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "  )\n",
      "  (upsample): Upsample(\n",
      "    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): PixelShuffle(upscale_factor=2)\n",
      "  )\n",
      "  (conv_last): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "2023-04-15 09:00:58,530 INFO: Loading HAT model from ./experiments/pretrained_models/HAT_SRx2_ImageNet-pretrain.pth, with param key: [params_ema].\n",
      "2023-04-15 09:00:58,592 INFO: Model [HATModel] is created.\n",
      "2023-04-15 09:00:58,592 INFO: Testing Set5...\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/bmd1905/Desktop/HAT/hat/test.py\", line 11, in <module>\n",
      "    test_pipeline(root_path)\n",
      "  File \"/Users/bmd1905/miniforge3/envs/yolov7_env/lib/python3.10/site-packages/basicsr/test.py\", line 40, in test_pipeline\n",
      "    model.validation(test_loader, current_iter=opt['name'], tb_logger=None, save_img=opt['val']['save_img'])\n",
      "  File \"/Users/bmd1905/miniforge3/envs/yolov7_env/lib/python3.10/site-packages/basicsr/models/base_model.py\", line 48, in validation\n",
      "    self.nondist_validation(dataloader, current_iter, tb_logger, save_img)\n",
      "  File \"/Users/bmd1905/Desktop/HAT/hat/models/hat_model.py\", line 140, in nondist_validation\n",
      "    self.process()\n",
      "  File \"/Users/bmd1905/Desktop/HAT/hat/models/hat_model.py\", line 37, in process\n",
      "    self.output = self.net_g(self.img)\n",
      "  File \"/Users/bmd1905/miniforge3/envs/yolov7_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/bmd1905/Desktop/HAT/hat/archs/hat_arch.py\", line 978, in forward\n",
      "    x = self.conv_after_body(self.forward_features(x)) + x\n",
      "  File \"/Users/bmd1905/Desktop/HAT/hat/archs/hat_arch.py\", line 964, in forward_features\n",
      "    x = layer(x, x_size, params)\n",
      "  File \"/Users/bmd1905/miniforge3/envs/yolov7_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/bmd1905/Desktop/HAT/hat/archs/hat_arch.py\", line 619, in forward\n",
      "    return self.patch_embed(self.conv(self.patch_unembed(self.residual_group(x, x_size, params), x_size))) + x\n",
      "  File \"/Users/bmd1905/miniforge3/envs/yolov7_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/bmd1905/Desktop/HAT/hat/archs/hat_arch.py\", line 528, in forward\n",
      "    x = blk(x, x_size, params['rpi_sa'], params['attn_mask'])\n",
      "  File \"/Users/bmd1905/miniforge3/envs/yolov7_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/bmd1905/Desktop/HAT/hat/archs/hat_arch.py\", line 307, in forward\n",
      "    x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
      "  File \"/Users/bmd1905/miniforge3/envs/yolov7_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/bmd1905/Desktop/HAT/hat/archs/hat_arch.py\", line 90, in forward\n",
      "    x = self.act(x)\n",
      "  File \"/Users/bmd1905/miniforge3/envs/yolov7_env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/bmd1905/miniforge3/envs/yolov7_env/lib/python3.10/site-packages/torch/nn/modules/activation.py\", line 685, in forward\n",
      "    return F.gelu(input, approximate=self.approximate)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python hat/test.py -opt options/test/HAT_SRx2_ImageNet-pretrain.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = glob('datasets/Set5/LRbicx2/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in img_paths:\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.resize(img, (768, 1024))\n",
    "\n",
    "    cv2.imwrite(path, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 1024)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "384*2, 512*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
